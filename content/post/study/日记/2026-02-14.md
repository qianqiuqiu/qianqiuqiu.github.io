---
title: 学习day25：
date: 2026-02-14
categories:
  - diary
tag:
  - diary
math: true
---
lc：287(快慢指针floyd判圈、二分查找计数都是空间复杂度O(1),个人更喜欢二分查找计数)
322、139、994

开始搞RAG的第二个项目，其实也不知道做这个到底有没有用，因为求职不一定找这个方向的，这个项目不打算做很深，放在简历上能说个七七八八就行了。

用AI 搓完了RAG的项目，明天仔细复盘

看猛猿的知乎文章，目前是打算全部看完。
## 【Git系列】 
老早就看过了，只是以前没注意作者名字。
## 【Transformer系列】
BN LN这一篇新东西比较多，位置编码从直观想法推导到Sin PE，结合attn影响引出RoPE， attn的过程这些都是老生常谈，或者说我前段时间刚学不久，大部分知识点、观点早已吸收过了。
LN使得各条数据间在进行标准化的时候相互独立，因此LN在训练和测试过程中是一致的。LN不需要保留训练过程中的 均值方差，每当来一条数据时，对这条数据的指定范围内单独计算所需统计量即可。

Pre-LN好，原始transformer中，采用的是Post-LN。Pre-LN不需要采用warm-up策略 Post-LN必须要使用warm-up策略才可以在数据集上取得较好的Loss和BLEU结果。 由于Pre-LN不采用warm-up，其一开始的learning rate较Post-LN更高，因此它的收敛速度更快。
Pre-LN带来的好处，基本都是因为不需要做warm-up引起的。而引起这一差异的根本原因是：

- Post-LN在输出层的gradient norm较大，且越往下层走，gradient norm呈现下降趋势。这种情况下，在训练初期若采用一个较大的学习率，容易引起模型的震荡。
- Pre-LN在输出层的gradient norm较小，且其不随层数递增或递减而变动，保持稳定。
- 无论使用何种Optimzer，不采用warm-up的Post-LN的效果都不如采用warm-up的情况，也不如Pre-LN。

resnet
因为梯度消失/爆炸所导致的深层网络模型不收敛的问题，已经得到了解决。那么现在新的问题出现了：**在模型能够收敛的情况下，网络越深，模型的准确率越低，同时，模型的准确率先达到饱和，此后迅速下降**。这个情况我们称之为**网络退化（Degradation）。**
借助神经网络中的非线形操作，可以帮助我们更好地拟合模型的特征。为了增加模型的表达能力，一种直觉的想法是，增加网络的深度，一来使得网络的每一层都尽量学到不同的模式，二来更好地利用网络的非线性拟合能力。
理想中的深网络，其表现不应该差于浅网络。毕竟表达能力更强，再不济齐平浅网络
核心$\mathcal{H}(X)=\mathcal{F}(X)+X$
在transformer的encoder和decoder中，各用到了6层的attention模块，每一个attention模块又和一个FeedForward层（简称FFN）相接。对每一层的attention和FFN，都采用了一次残差连接，即把每一个位置的输入数据和输出数据相加，使得Transformer能够有效训练更深的网络。在残差连接过后，再采取Layer Nomalization的方式。

BERT精读
它能抽取出基于上下文的word embedding
BERT模型的内部其实就是transformer encoder层。**BERT是双向的**。BERT在做attention的时候，会atten到一个token左、右两边的部分。 
**BERT是无监督的**。 
**BERT是fine-tuning的预训练模型**。

Transformer处理可变长度数据
**Transformer中的参数矩阵维度与输入序列的长度无关**
**“长短极不均衡”确实会拖慢训练、浪费算力，并且在某些设置下会让优化变差**。padding token 必须被 mask 掉。 如果把 max_len 设成 300，为了容纳那 10%，那么 90% 的短句每条只有 10 个 token，剩下 290 都是 pad。
常见操作是按 batch 内最大长度动态 padding（dynamic padding），还有一些桶排等batch层次的分组优化操作balabala。
就是靠M mask来消除长短不一的padding带来的影响。

标准 self-attention:
$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}} + M\right)V$$
其中：
- $QK^T$: 所有 token 两两算相似度（包括 pad）
- $M$: attention mask
- padding 位置设为 $-\infty$，softmax之后就是0，不影响概率分布。
- 非 padding 位置设为 0



