---
title: "转码学习day2"
date: 2026-01-22
categories:
    - diary
tags:
    - diary
---

睡到中午起床，下午两点半开始学习。

lc：41、160、206、234、141、142

下午和晚上陆续地手搓了完整的transformer，一口气把所有不懂的语法规则以及用到的pytorch规则全弄懂了。

了解到 pre LN和 post LN（已过时），二者在残差连接结构下效果差异显著，超过12层，后者可训练能力就变差了。

之前一直没在意Embedding地时候也要乘上math.sqrt(*self*.d_model)，它和注意力的根号dk都是为了放缩信号，使得梯度训练能持续进行下去，避免梯度消失或者爆炸。

感觉稍微抓到了一点OOP的精髓，这样子写确实不好弄懂，对我一个newcomer来说不沉下心来的话。但是弄懂了之后，这种写法确实对代码美观优化挺多啊，便于思考项目的整体架构。

今天先到这，明天继续。
